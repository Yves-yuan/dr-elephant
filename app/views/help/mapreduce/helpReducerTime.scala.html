@*
* Copyright 2016 LinkedIn Corp.
*
* Licensed under the Apache License, Version 2.0 (the "License"); you may not
* use this file except in compliance with the License. You may obtain a copy of
* the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
* License for the specific language governing permissions and limitations under
* the License.
*@

<p>
    This analysis shows the efficiency of your reducers.<br>
    This should allow you to better adjust the number of reducers for your job.<br>
    There are two possible situations that needs some tuning.
</p>
<h3>Too many reducers</h3>
<p>
    This happens when the Hadoop job has:
    <ul>
        <li>A <b>large</b> number of reducers</li>
        <li><b>Short</b> reducer runtime</li>
    </ul>
</p>
<h5>Example</h5>
<p>
    <div class="list-group">
        <a class="list-group-item list-group-item-danger" href="#">
            <h4 class="list-group-item-heading">Reducer Time</h4>
            <table class="list-group-item-text table table-condensed left-table">
                <thead><tr><th colspan="2">Severity: Critical</th></tr></thead>
                <tbody>
                <tr>
                    <td>Number of tasks</td>
                    <td>1000</td>
                </tr>
                <tr>
                    <td>Average task time</td>
                    <td>25sec</td>
                </tr>
                </tbody>
            </table>
        </a>
    </div>
</p>
<h3>Too few reducers</h3>
<p>
    This happens when the Hadoop job has:
    <ul>
        <li>A <b>small</b> number of reducers</li>
        <li><b>Long</b> reducer runtime</li>
    </ul>
</p>
<h5>Example</h5>
<p>
    <div class="list-group">
        <a class="list-group-item list-group-item-danger" href="#">
            <h4 class="list-group-item-heading">Reducer Time</h4>
            <table class="list-group-item-text table table-condensed left-table">
                <thead><tr><th colspan="2">Severity: Critical</th></tr></thead>
                <tbody>
                <tr>
                    <td>Number of tasks</td>
                    <td>8</td>
                </tr>
                <tr>
                    <td>Average task time</td>
                    <td>2hr 47min 11sec</td>
                </tr>
                </tbody>
            </table>
        </a>
    </div>
</p>
<h3>Suggestions</h3>
<p>
    Set the number of reducers by specifying a better number in your Hadoop job.<br>
    <br>
    For Hadoop/Java jobs: Use "jobConf.setNumReduceTasks(NUMBER_OF_REDUCERS);"<br>
    For Apache-Pig jobs: Use PARALLEL [num] clause on the operator which caused this job (Though this will probably be hard for people to understand without Lipstick)<br>
    For Apache-Hive jobs: Use "set mapreduce.job.reduces=NUMBER_OF_REDUCERS"<br>
    For Azkaban flows, add jvm.args=-Dmapreduce.job.reduces=NUMBER_OF_REDUCERS to your job properties<br>
    <br>
    Generally, Dr. Elephant(and Hadoop team) advises the ideal task time to be 5-10 minutes.<br>
    See <a href="https://github.com/linkedin/dr-elephant/wiki/Tuning-Tips">Hadoop Tuning Tips</a> for further information.
</p>